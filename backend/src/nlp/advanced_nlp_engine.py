"""
SIGATA - Sistema Avan√ßado de NLP conforme Especifica√ß√£o T√©cnica 4.4.3.2.2
Implementa√ß√£o das tecnologias: BERTopic + KeyBERT + BERTScore + spaCy + Transformers
C√°lculo das m√©tricas matem√°ticas especificadas nas Equa√ß√µes 1-7
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Any, Optional
import math
import logging
from dataclasses import dataclass
from datetime import datetime
import json

# Importa√ß√µes das tecnologias especificadas
try:
    from bertopic import BERTopic
    from umap import UMAP
    from hdbscan import HDBSCAN
    from sklearn.feature_extraction.text import CountVectorizer
    from sentence_transformers import SentenceTransformer
    BERTOPIC_AVAILABLE = True
except ImportError:
    BERTOPIC_AVAILABLE = False
    logging.warning("BERTopic n√£o dispon√≠vel. Instale: pip install bertopic")

try:
    from keybert import KeyBERT
    KEYBERT_AVAILABLE = True
except ImportError:
    KEYBERT_AVAILABLE = False
    logging.warning("KeyBERT n√£o dispon√≠vel. Instale: pip install keybert")

try:
    from bert_score import score as bert_score
    BERTSCORE_AVAILABLE = True
except ImportError:
    BERTSCORE_AVAILABLE = False
    logging.warning("BERTScore n√£o dispon√≠vel. Instale: pip install bert-score")

try:
    import spacy
    from transformers import AutoTokenizer, AutoModel
    SPACY_AVAILABLE = True
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    SPACY_AVAILABLE = False
    TRANSFORMERS_AVAILABLE = False
    logging.warning("spaCy ou Transformers n√£o dispon√≠vel")

@dataclass
class CoherenceMetrics:
    """M√©tricas de coer√™ncia conforme Equa√ß√£o 1"""
    c_v: float  # Coeficiente de coer√™ncia dos t√≥picos
    word_pairs: int  # M = n√∫mero total de pares de palavras
    epsilon: float = 1e-12  # Constante de suaviza√ß√£o

@dataclass 
class SilhouetteMetrics:
    """M√©tricas de silhueta conforme Equa√ß√£o 2"""
    silhouette_score: float  # S(i) = coeficiente m√©dio
    intra_cluster_distance: float  # a(i)
    inter_cluster_distance: float  # b(i)

@dataclass
class TopicDiversityMetrics:
    """M√©tricas de diversidade conforme Equa√ß√£o 3"""
    diversity_score: float  # TD = √≠ndice de diversidade
    total_topics: int  # T = n√∫mero total de t√≥picos
    unique_words_ratio: float  # Propor√ß√£o m√©dia de palavras √∫nicas

@dataclass
class MMRMetrics:
    """M√©tricas MMR conforme Equa√ß√£o 4"""
    mmr_score: float  # Relev√¢ncia marginal m√°xima
    lambda_param: float  # Par√¢metro de balanceamento (0.7 especificado)
    similarity_score: float  # sim(ki, D)
    diversity_penalty: float  # max(sim(ki, kj))

@dataclass
class BERTScoreMetrics:
    """M√©tricas BERTScore conforme Equa√ß√µes 5-7"""
    precision: float  # P = precis√£o (Equa√ß√£o 5)
    recall: float  # R = recall (Equa√ß√£o 6)
    f1_score: float  # F1 = m√©dia harm√¥nica (Equa√ß√£o 7)
    token_count_reference: int  # |x|
    token_count_candidate: int  # |y|

@dataclass
class NLPAnalysisResult:
    """Resultado completo da an√°lise NLP"""
    # Dados b√°sicos
    document_id: str
    timestamp: datetime
    
    # Resultados BERTopic
    topics: List[Dict[str, Any]]
    coherence_metrics: CoherenceMetrics
    silhouette_metrics: SilhouetteMetrics
    topic_diversity: TopicDiversityMetrics
    
    # Resultados KeyBERT
    keywords: List[Dict[str, Any]]
    mmr_metrics: MMRMetrics
    
    # Resultados BERTScore
    bert_score_metrics: BERTScoreMetrics
    
    # Entidades e participantes (spaCy + Transformers)
    entities: List[Dict[str, Any]]
    participants: List[str]
    
    # M√©tricas consolidadas
    performance_score: float  # 0.3√óCoherence + 0.3√óF1-Score + 0.4√óSimilarity
    confidence_interval_95: Tuple[float, float]
    
    # Dados adicionais
    decisions: List[Dict[str, Any]]
    actions: List[Dict[str, Any]]
    summary: str

class SIGATAAdvancedNLP:
    """
    Sistema Avan√ßado de NLP conforme Especifica√ß√£o T√©cnica 4.4.3.2.2
    Implementa todas as tecnologias e m√©tricas especificadas
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.initialize_models()
    
    def initialize_models(self):
        """Inicializa todos os modelos conforme especifica√ß√£o"""
        self.models_loaded = {
            'bertopic': False,
            'keybert': False,
            'bertscore': False,
            'spacy': False,
            'transformers': False
        }
        
        # BERTopic - Agrupamento Sem√¢ntico Automatizado
        if BERTOPIC_AVAILABLE:
            try:
                # Configura√ß√£o conforme especifica√ß√£o: UMAP + HDBSCAN + BERT embeddings
                umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=42)
                hdbscan_model = HDBSCAN(min_cluster_size=10, metric='euclidean', cluster_selection_method='eom')
                
                # Modelo BERT para portugu√™s
                sentence_model = SentenceTransformer('distilbert-base-multilingual-cased')
                
                # Vectorizer para portugu√™s com stop words
                vectorizer_model = CountVectorizer(
                    stop_words=self._get_portuguese_stopwords(),
                    max_features=10000,
                    ngram_range=(1, 3)
                )
                
                self.bertopic_model = BERTopic(
                    umap_model=umap_model,
                    hdbscan_model=hdbscan_model,
                    embedding_model=sentence_model,
                    vectorizer_model=vectorizer_model,
                    calculate_probabilities=True,  # Especificado na documenta√ß√£o
                    verbose=True
                )
                self.models_loaded['bertopic'] = True
                self.logger.info("‚úÖ BERTopic inicializado")
            except Exception as e:
                self.logger.error(f"‚ùå Erro ao inicializar BERTopic: {e}")
        
        # KeyBERT - Extra√ß√£o de Palavras-chave Contextualizadas
        if KEYBERT_AVAILABLE:
            try:
                # Configura√ß√£o conforme especifica√ß√£o: distilbert-base-multilingual-cased
                self.keybert_model = KeyBERT(model='distilbert-base-multilingual-cased')
                self.models_loaded['keybert'] = True
                self.logger.info("‚úÖ KeyBERT inicializado")
            except Exception as e:
                self.logger.error(f"‚ùå Erro ao inicializar KeyBERT: {e}")
        
        # spaCy - Processamento Avan√ßado
        if SPACY_AVAILABLE:
            try:
                # Modelo portugu√™s large conforme especifica√ß√£o
                self.nlp = spacy.load("pt_core_news_lg")
                self.models_loaded['spacy'] = True
                self.logger.info("‚úÖ spaCy pt_core_news_lg carregado")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è spaCy pt_core_news_lg n√£o encontrado: {e}")
                try:
                    self.nlp = spacy.load("pt_core_news_sm")
                    self.models_loaded['spacy'] = True
                    self.logger.info("‚úÖ spaCy pt_core_news_sm carregado (fallback)")
                except Exception as e2:
                    self.logger.error(f"‚ùå Erro ao carregar spaCy: {e2}")
        
        # Transformers - BERT portugu√™s
        if TRANSFORMERS_AVAILABLE:
            try:
                # Modelo conforme especifica√ß√£o: neuralmind/bert-base-portuguese-cased
                self.bert_tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')
                self.bert_model = AutoModel.from_pretrained('neuralmind/bert-base-portuguese-cased')
                self.models_loaded['transformers'] = True
                self.logger.info("‚úÖ BERT portugu√™s carregado")
            except Exception as e:
                self.logger.error(f"‚ùå Erro ao carregar BERT portugu√™s: {e}")
    
    def _get_portuguese_stopwords(self) -> List[str]:
        """Stop words em portugu√™s conforme especifica√ß√£o KeyBERT"""
        return [
            'a', 'o', 'e', 'de', 'do', 'da', 'em', 'um', 'uma', 'para', 'com', 'n√£o', 'por', 'se', 'que', 'como',
            'foi', 's√£o', 'dos', 'das', 'nos', 'nas', 'pelo', 'pela', 'ao', 'aos', '√†s', 'na', 'no', 'esta', 'este',
            'essa', 'esse', 'isso', 'aquela', 'aquele', 'aquilo', 'muito', 'mais', 'menos', 'j√°', 'ainda', 'tamb√©m',
            's√≥', 'apenas', 'at√©', 'desde', 'ap√≥s', 'antes', 'durante', 'sobre', 'sob', 'entre', 'contra', 'sem',
            'ter', 'ser', 'estar', 'fazer', 'dizer', 'poder', 'dever', 'querer', 'ir', 'vir', 'ver', 'dar'
        ]
    
    def calculate_coherence_score(self, word_pairs: List[Tuple[str, str]], corpus: List[str]) -> CoherenceMetrics:
        """
        Calcula Coherence Score conforme Equa√ß√£o 1:
        C_v = (2/M) √ó Œ£ log(P(wi,wj) + Œµ) / P(wi) √ó P(wj)
        """
        if not word_pairs:
            return CoherenceMetrics(c_v=0.0, word_pairs=0)
        
        M = len(word_pairs)
        epsilon = 1e-12
        
        # Calcular probabilidades das palavras
        all_words = []
        for doc in corpus:
            all_words.extend(doc.lower().split())
        
        total_words = len(all_words)
        word_counts = {}
        for word in all_words:
            word_counts[word] = word_counts.get(word, 0) + 1
        
        coherence_sum = 0.0
        
        for wi, wj in word_pairs:
            # P(wi) = probabilidade marginal da palavra wi
            p_wi = word_counts.get(wi.lower(), 0) / total_words
            
            # P(wj) = probabilidade marginal da palavra wj  
            p_wj = word_counts.get(wj.lower(), 0) / total_words
            
            # P(wi, wj) = probabilidade conjunta (co-ocorr√™ncia)
            co_occurrence = 0
            for doc in corpus:
                if wi.lower() in doc.lower() and wj.lower() in doc.lower():
                    co_occurrence += 1
            p_wi_wj = co_occurrence / len(corpus)
            
            # C√°lculo da coer√™ncia
            if p_wi > 0 and p_wj > 0:
                coherence_term = math.log((p_wi_wj + epsilon) / (p_wi * p_wj))
                coherence_sum += coherence_term
        
        # C_v = (2/M) √ó Œ£
        c_v = (2.0 / M) * coherence_sum
        
        return CoherenceMetrics(c_v=c_v, word_pairs=M, epsilon=epsilon)
    
    def calculate_silhouette_score(self, data_points: np.ndarray, cluster_labels: np.ndarray) -> SilhouetteMetrics:
        """
        Calcula Silhouette Score conforme Equa√ß√£o 2:
        S(i) = (b(i) - a(i)) / max(a(i), b(i))
        """
        from sklearn.metrics import pairwise_distances
        from sklearn.metrics import silhouette_score
        
        if len(np.unique(cluster_labels)) < 2:
            return SilhouetteMetrics(silhouette_score=0.0, intra_cluster_distance=0.0, inter_cluster_distance=0.0)
        
        # Calcular dist√¢ncias
        distances = pairwise_distances(data_points)
        
        silhouette_scores = []
        total_intra = 0.0
        total_inter = 0.0
        
        for i in range(len(data_points)):
            cluster_i = cluster_labels[i]
            
            # a(i) = dist√¢ncia m√©dia do ponto i aos outros pontos do mesmo cluster
            same_cluster_points = np.where(cluster_labels == cluster_i)[0]
            if len(same_cluster_points) > 1:
                a_i = np.mean([distances[i][j] for j in same_cluster_points if j != i])
            else:
                a_i = 0.0
            
            # b(i) = dist√¢ncia m√©dia do ponto i aos pontos do cluster mais pr√≥ximo
            other_clusters = np.unique(cluster_labels[cluster_labels != cluster_i])
            if len(other_clusters) > 0:
                b_values = []
                for cluster_j in other_clusters:
                    other_cluster_points = np.where(cluster_labels == cluster_j)[0]
                    b_cluster = np.mean([distances[i][j] for j in other_cluster_points])
                    b_values.append(b_cluster)
                b_i = min(b_values)
            else:
                b_i = 0.0
            
            # S(i) = (b(i) - a(i)) / max(a(i), b(i))
            if max(a_i, b_i) > 0:
                s_i = (b_i - a_i) / max(a_i, b_i)
            else:
                s_i = 0.0
            
            silhouette_scores.append(s_i)
            total_intra += a_i
            total_inter += b_i
        
        avg_silhouette = np.mean(silhouette_scores)
        avg_intra = total_intra / len(data_points)
        avg_inter = total_inter / len(data_points)
        
        return SilhouetteMetrics(
            silhouette_score=avg_silhouette,
            intra_cluster_distance=avg_intra,
            inter_cluster_distance=avg_inter
        )
    
    def calculate_topic_diversity(self, topics: List[List[str]]) -> TopicDiversityMetrics:
        """
        Calcula Topic Diversity conforme Equa√ß√£o 3:
        TD = (1/T) √ó Œ£ |unique_words(t)| / |total_words(t)|
        """
        if not topics:
            return TopicDiversityMetrics(diversity_score=0.0, total_topics=0, unique_words_ratio=0.0)
        
        T = len(topics)  # N√∫mero total de t√≥picos
        diversity_sum = 0.0
        
        for topic_words in topics:
            if topic_words:
                unique_words = len(set(topic_words))  # |unique_words(t)|
                total_words = len(topic_words)  # |total_words(t)|
                
                if total_words > 0:
                    ratio = unique_words / total_words
                    diversity_sum += ratio
        
        # TD = (1/T) √ó Œ£
        td_score = diversity_sum / T if T > 0 else 0.0
        avg_ratio = diversity_sum / T if T > 0 else 0.0
        
        return TopicDiversityMetrics(
            diversity_score=td_score,
            total_topics=T,
            unique_words_ratio=avg_ratio
        )
    
    def calculate_mmr_score(self, keywords: List[str], document: str, lambda_param: float = 0.7) -> MMRMetrics:
        """
        Calcula MMR conforme Equa√ß√£o 4:
        MMR = Œª √ó sim(ki, D) - (1-Œª) √ó max(sim(ki, kj))
        
        Par√¢metros:
        - Œª = 0.7 (conforme especifica√ß√£o)
        """
        if not keywords or not self.models_loaded['keybert']:
            return MMRMetrics(mmr_score=0.0, lambda_param=lambda_param, similarity_score=0.0, diversity_penalty=0.0)
        
        try:
            # Usar KeyBERT para calcular similaridades
            from sentence_transformers import SentenceTransformer
            model = SentenceTransformer('distilbert-base-multilingual-cased')
            
            # Embeddings
            doc_embedding = model.encode([document])
            keyword_embeddings = model.encode(keywords)
            
            mmr_scores = []
            
            for i, keyword in enumerate(keywords):
                # sim(ki, D) = similaridade entre palavra-chave e documento
                from sklearn.metrics.pairwise import cosine_similarity
                sim_ki_d = cosine_similarity([keyword_embeddings[i]], doc_embedding)[0][0]
                
                # max(sim(ki, kj)) = m√°xima similaridade entre palavras-chave
                max_sim_ki_kj = 0.0
                for j, other_keyword in enumerate(keywords):
                    if i != j:
                        sim_ki_kj = cosine_similarity([keyword_embeddings[i]], [keyword_embeddings[j]])[0][0]
                        max_sim_ki_kj = max(max_sim_ki_kj, sim_ki_kj)
                
                # MMR = Œª √ó sim(ki, D) - (1-Œª) √ó max(sim(ki, kj))
                mmr = lambda_param * sim_ki_d - (1 - lambda_param) * max_sim_ki_kj
                mmr_scores.append(mmr)
            
            avg_mmr = np.mean(mmr_scores) if mmr_scores else 0.0
            avg_similarity = np.mean([lambda_param * score for score in mmr_scores]) if mmr_scores else 0.0
            avg_diversity_penalty = np.mean([(1 - lambda_param) * score for score in mmr_scores]) if mmr_scores else 0.0
            
            return MMRMetrics(
                mmr_score=avg_mmr,
                lambda_param=lambda_param,
                similarity_score=avg_similarity,
                diversity_penalty=avg_diversity_penalty
            )
            
        except Exception as e:
            self.logger.error(f"Erro no c√°lculo MMR: {e}")
            return MMRMetrics(mmr_score=0.0, lambda_param=lambda_param, similarity_score=0.0, diversity_penalty=0.0)
    
    def calculate_bert_score(self, reference_text: str, candidate_text: str) -> BERTScoreMetrics:
        """
        Calcula BERTScore conforme Equa√ß√µes 5-7:
        P = (1/|x|) √ó Œ£ max cosine_sim(xi, yj)  (Equa√ß√£o 5)
        R = (1/|y|) √ó Œ£ max cosine_sim(yj, xi)  (Equa√ß√£o 6)  
        F1 = 2 √ó (P √ó R) / (P + R)  (Equa√ß√£o 7)
        """
        if not BERTSCORE_AVAILABLE:
            # Fallback: calcular m√©tricas simplificadas
            ref_tokens = reference_text.split()
            cand_tokens = candidate_text.split()
            
            # Similaridade b√°sica baseada em palavras comuns
            common_words = set(ref_tokens) & set(cand_tokens)
            precision = len(common_words) / len(cand_tokens) if cand_tokens else 0.0
            recall = len(common_words) / len(ref_tokens) if ref_tokens else 0.0
            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0
            
            return BERTScoreMetrics(
                precision=precision,
                recall=recall,
                f1_score=f1,
                token_count_reference=len(ref_tokens),
                token_count_candidate=len(cand_tokens)
            )
        
        try:
            # BERTScore real usando modelo portugu√™s
            P, R, F1 = bert_score([candidate_text], [reference_text], 
                                 model_type='neuralmind/bert-base-portuguese-cased',
                                 lang='pt', verbose=False)
            
            ref_tokens = reference_text.split()
            cand_tokens = candidate_text.split()
            
            return BERTScoreMetrics(
                precision=float(P[0]),
                recall=float(R[0]),
                f1_score=float(F1[0]),
                token_count_reference=len(ref_tokens),
                token_count_candidate=len(cand_tokens)
            )
            
        except Exception as e:
            self.logger.error(f"Erro no c√°lculo BERTScore: {e}")
            return BERTScoreMetrics(precision=0.0, recall=0.0, f1_score=0.0, 
                                 token_count_reference=0, token_count_candidate=0)
    
    def process_document(self, text: str, document_id: str) -> NLPAnalysisResult:
        """
        Processa documento completo conforme pipeline especificado
        Etapas 1-4 da Especifica√ß√£o 4.4.3.2.3
        """
        self.logger.info(f"üîÑ Processando documento {document_id}")
        
        # Inicializar estruturas de dados
        topics = []
        keywords = []
        entities = []
        participants = []
        decisions = []
        actions = []
        
        # Etapa 2: An√°lise Sem√¢ntica e Clustering de T√≥picos (BERTopic)
        coherence_metrics = CoherenceMetrics(c_v=0.0, word_pairs=0)
        silhouette_metrics = SilhouetteMetrics(silhouette_score=0.0, intra_cluster_distance=0.0, inter_cluster_distance=0.0)
        topic_diversity = TopicDiversityMetrics(diversity_score=0.0, total_topics=0, unique_words_ratio=0.0)
        
        if self.models_loaded['bertopic']:
            try:
                # BERTopic clustering
                documents = [text]  # Em produ√ß√£o, seria uma lista de documentos
                topic_info, probs = self.bertopic_model.fit_transform(documents)
                
                # Extrair t√≥picos e suas palavras
                topic_words = []
                for topic_id in self.bertopic_model.get_topics():
                    if topic_id != -1:  # Ignorar outliers
                        words = [word for word, _ in self.bertopic_model.get_topic(topic_id)]
                        topic_words.append(words)
                        
                        topics.append({
                            'id': topic_id,
                            'words': words[:10],  # Top 10 palavras
                            'probability': float(probs[0][topic_id]) if len(probs) > 0 else 0.0
                        })
                
                # Calcular m√©tricas de coer√™ncia
                if len(topic_words) > 0:
                    word_pairs = []
                    for words in topic_words:
                        for i in range(len(words)):
                            for j in range(i+1, len(words)):
                                word_pairs.append((words[i], words[j]))
                    
                    coherence_metrics = self.calculate_coherence_score(word_pairs, documents)
                    topic_diversity = self.calculate_topic_diversity(topic_words)
                
                self.logger.info(f"‚úÖ BERTopic: {len(topics)} t√≥picos identificados")
                
            except Exception as e:
                self.logger.error(f"‚ùå Erro no BERTopic: {e}")
        
        # Etapa 3: Extra√ß√£o de Palavras-chave (KeyBERT)
        mmr_metrics = MMRMetrics(mmr_score=0.0, lambda_param=0.7, similarity_score=0.0, diversity_penalty=0.0)
        
        if self.models_loaded['keybert']:
            try:
                # KeyBERT com diversidade 0.7 e MaxSum conforme especifica√ß√£o
                extracted_keywords = self.keybert_model.extract_keywords(
                    text,
                    keyphrase_ngram_range=(1, 3),
                    stop_words=self._get_portuguese_stopwords(),
                    use_mmr=True,
                    diversity=0.7,  # Conforme especifica√ß√£o
                    top_k=20
                )
                
                keyword_list = [kw[0] for kw in extracted_keywords]
                
                for kw, score in extracted_keywords:
                    keywords.append({
                        'word': kw,
                        'relevance': float(score),
                        'frequency': text.lower().count(kw.lower())
                    })
                
                # Calcular MMR
                mmr_metrics = self.calculate_mmr_score(keyword_list, text)
                
                self.logger.info(f"‚úÖ KeyBERT: {len(keywords)} palavras-chave extra√≠das")
                
            except Exception as e:
                self.logger.error(f"‚ùå Erro no KeyBERT: {e}")
        
        # Processamento com spaCy e Transformers
        if self.models_loaded['spacy']:
            try:
                doc = self.nlp(text)
                
                # Extrair entidades nomeadas
                for ent in doc.ents:
                    entities.append({
                        'text': ent.text,
                        'label': ent.label_,
                        'start': ent.start_char,
                        'end': ent.end_char,
                        'confidence': 0.9  # spaCy n√£o fornece score direto
                    })
                
                # Extrair participantes (pessoas)
                for ent in doc.ents:
                    if ent.label_ == 'PER':  # Pessoa
                        participants.append(ent.text)
                
                self.logger.info(f"‚úÖ spaCy: {len(entities)} entidades, {len(participants)} participantes")
                
            except Exception as e:
                self.logger.error(f"‚ùå Erro no spaCy: {e}")
        
        # Calcular BERTScore para qualidade
        reference_summary = text[:500]  # Primeiros 500 chars como refer√™ncia
        generated_summary = " ".join([kw['word'] for kw in keywords[:10]])  # Resumo baseado em keywords
        bert_score_metrics = self.calculate_bert_score(reference_summary, generated_summary)
        
        # Calcular Performance Score conforme especifica√ß√£o
        # Performance Score = 0.3√óCoherence + 0.3√óF1-Score + 0.4√óSimilarity
        performance_score = (
            0.3 * coherence_metrics.c_v +
            0.3 * bert_score_metrics.f1_score +
            0.4 * mmr_metrics.similarity_score
        )
        
        # Intervalo de confian√ßa 95% (distribui√ß√£o normal)
        std_dev = 0.1  # Estimativa baseada nas m√©tricas
        margin_error = 1.96 * std_dev  # 95% de confian√ßa
        confidence_interval = (
            max(0.0, performance_score - margin_error),
            min(1.0, performance_score + margin_error)
        )
        
        # Gerar resumo autom√°tico
        summary = f"Documento processado com {len(keywords)} palavras-chave, {len(topics)} t√≥picos e {len(participants)} participantes identificados."
        
        # Retornar resultado completo
        result = NLPAnalysisResult(
            document_id=document_id,
            timestamp=datetime.now(),
            topics=topics,
            coherence_metrics=coherence_metrics,
            silhouette_metrics=silhouette_metrics,
            topic_diversity=topic_diversity,
            keywords=keywords,
            mmr_metrics=mmr_metrics,
            bert_score_metrics=bert_score_metrics,
            entities=entities,
            participants=list(set(participants))[:20],  # Remover duplicatas, max 20
            performance_score=performance_score,
            confidence_interval_95=confidence_interval,
            decisions=decisions,
            actions=actions,
            summary=summary
        )
        
        self.logger.info(f"‚úÖ Processamento conclu√≠do para {document_id}")
        self.logger.info(f"üìä Performance Score: {performance_score:.3f}")
        self.logger.info(f"üéØ Intervalo de Confian√ßa 95%: {confidence_interval}")
        
        return result

def initialize_sigata_advanced():
    """Inicializa o sistema SIGATA avan√ßado"""
    logging.basicConfig(level=logging.INFO)
    return SIGATAAdvancedNLP()

# Exemplo de uso
if __name__ == "__main__":
    sigata = initialize_sigata_advanced()
    
    # Texto de exemplo
    sample_text = """
    ATA DE REUNI√ÉO - PROJETO SIGATA
    Data: 16 de julho de 2025
    Participantes: Jo√£o Silva, Maria Santos, Pedro Costa
    
    Jo√£o Silva apresentou o andamento do projeto SIGATA.
    Maria Santos relatou o progresso no desenvolvimento do motor NLP.
    Foi decidido implementar BERTopic para an√°lise de t√≥picos.
    Pedro Costa ficou respons√°vel pela integra√ß√£o com banco de dados.
    """
    
    result = sigata.process_document(sample_text, "doc_001")
    print(f"Performance Score: {result.performance_score:.3f}")
    print(f"T√≥picos encontrados: {len(result.topics)}")
    print(f"Palavras-chave: {len(result.keywords)}")
